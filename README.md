# NLP Comparison of Models to Create a Survey Dialog Bot

## Background
The goal of this exercise is to determine which classification technique can generate an accurate survey dialog for a restaurant business to better understand their customers. The most efficient model will be used to power an application that captures the sentiment of its customers and ranks them based on the underlying sentiment dataset. Appropriate responses will be generated by the application based on the response rankings to complete the survey dialog. The classification techniques to be tested are: Random Forest Classification, Logistic Regression and Na√Øve Bayes Classification.

## Data Source and Cleaning
The Yelp review data was taken from Zhenyu Fan (https://www.kaggle.com/zhenyufan/nlp-for-yelp-reviews?select=yelp.csv). It contained a heavy bias for 5-star and 4-star ratings, which was not fully removed during cleaning. The focus was on comparing various models. However, a better dataset should be used in future versions of this investigation. Several dialog responses were constructed from the star classification rankings. A more detailed report can be seen in the pdf file.

## File Dictionary
- The yelp.csv file contained the data to train and validate the various models against.
- The models were compared in the nlp_model_tests.py file.
- The selected model was isolated in the logisticRegressionModel.joblib to speed up the execution of the classification. If using this file, it needs to be recreated from the nlp-model_tests.py.
- The bot_response.json file contained the pre-constructed responses, based on the star rating.
- The survey_dialog_bot.py file contains a TKinter application that takes text responses in three categories and returns an appropriate chatbot response.
- The NLP_modeling.pdf contains the statistical analysis and findings from various texts entered into the application.